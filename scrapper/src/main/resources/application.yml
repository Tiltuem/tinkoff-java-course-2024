app:
  scheduler:
    enable: true
    invoke-interval: 10s
    force-check-delay: 10s
    checkInterval: 600s
  database-access-type: jdbc
  retry:
    scrapper:
      http-statuses: 429, 500, 502, 503, 504
      type: linear
      max-attempts: 10
      config:
        initial-interval-millis: 5000
        max-interval-millis: 50000
        multiplier: 2
    bot:
      http-statuses: 429, 500
      type: linear
      max-attempts: 10
      config:
        initial-interval-millis: 5000
        max-interval-millis: 50000
        multiplier: 2
  use-queue: true
  kafka-config:
    servers: localhost:9091,localhost:9092,localhost:9093
    updates-topic:
      name: updates
      partitions: 2
      replicas: 2

spring:
  application:
    name: scrapper
  datasource:
    url: jdbc:postgresql://localhost:5432/scrapper
    username: postgres
    password: postgres
  jpa:
    hibernate:
      ddl-auto: validate
  liquibase:
    enabled: false
  cache:
    cache-names:
      - scrapper-rate-limit
    caffeine:
      spec: maximumSize=200000,expireAfterAccess=60s


server:
  port: 8080

logging:
  config: classpath:log4j2-plain.xml

github:
  base:
    url: "https://api.github.com"

stackOverflow:
  base:
    url: "https://api.stackexchange.com/2.3"

bot:
  base:
    url: http://localhost:8090


bucket4j:
  filters:
    - cache-name: scrapper-rate-limit
      http-response-body: "{ \"status\": 429, \"error\": \"Too Many Requests\", \"message\": \"Too Many Requests\" }"
      rate-limits:
        - bandwidths:
            - capacity: 100
              refill-speed: interval
              time: 1
              unit: minutes
      url: /.*

management:
  server:
    port: 8081
  endpoints:
    web:
      base-path: /
      path-mapping:
        prometheus: metrics
      exposure:
        include: health,info,prometheus
    enabled-by-default: false
  endpoint:
    info:
      enabled: true
    health:
      enabled: true
    prometheus:
      enabled: true
  metrics:
    tags:
      application: ${spring.application.name}
